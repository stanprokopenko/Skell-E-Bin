<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Skell-E HTML Preview</title>
  <link rel="stylesheet" href="../assets/style.css">
</head>
<body>
  <article>
    <header>
        <h1 id="title">OpenAI Employee ACCIDENTALLY REVEALS Q* Details! (Open AI Q*)</h1>
        <a href="#" class="button copy-link" onclick="copyToClipboard(); return false;">Copy Code</a>
    </header>
    <main id="code-to-copy" class="container">
<p>I recently came across a deleted tweet by Noan Brown, an AI researcher at OpenAI, that has sparked speculation in the AI community. The tweet mentioned that "superhuman performance" cannot be achieved by "better imitation learning on human data." Many believe this tweet could be related to OpenAI's rumored Q-star model, which allegedly involves planning and synthetic data.</p>

<p><strong>Noan Brown's background and previous tweets</strong></p>

<p>Noan Brown is known for his contributions to AI in imperfect information games, such as poker and diplomacy. In earlier tweets, he expressed excitement about joining OpenAI and the potential for LLMs to become "a thousand times better than GPT-4."</p>

<h2>The Importance of Planning and Inference Time in AI Models</h2>

<p>The concept of giving AI models more time to "think" or "plan" during inference has gained traction recently. Examples from AlphaGo and poker AI have shown that planning can lead to significant performance improvements. However, there is a trade-off between inference speed and accuracy in AI applications. Slower but more accurate AI models could be valuable in certain applications, such as writing contracts, discovering new drugs, or proving mathematical hypotheses.</p>

<p><strong>Noan Brown's interview on planning in AI models</strong></p>

<p>In an interview, Noan Brown shared his thoughts on the potential of planning in language models. He highlighted the limitations of scaling up models during pre-training and the need for alternative approaches. One idea he proposed was increasing inference cost to achieve better performance, equivalent to scaling up model size and training.</p>

<h2>OpenAI's Q-star Model and Synthetic Data</h2>

<p>OpenAI's rumored breakthrough with the Q-star model involves using computer-generated (synthetic) data to train new models, overcoming limitations on obtaining high-quality real-world data. There is speculation that the Q-star model involves planning and synthetic data, potentially linked to Noan Brown's deleted tweet.</p>

<h2>Examples of AI Systems with Planning Capabilities</h2>

<ul>

<li><strong>Mesa's KPU</strong>: An AI agent built on top of the GPT-4 stack, capable of multi-step reasoning and planning.</li>

<li><strong>Anthropic's Claude</strong>: An AI software engineer with an internal "scratch pad" for planning and executing tasks.</li>

</ul>

<p>There is potential for future AI models, such as GPT-5, to incorporate native planning capabilities or be released in separate, more agentic versions.</p>

<p>The deleted tweet by Noan Brown has sparked interesting discussions about the future of AI models and the role of planning and synthetic data in achieving "superhuman performance." As OpenAI continues to work on their rumored Q-star model, it will be fascinating to see how these concepts are implemented and the impact they will have on the AI landscape.</p>
    </main>
  </article>
  <footer><span class="skell-e-sig">&Sigma;&lt;3||-E</p></footer>
  <script src="../assets/script.js"></script>
</body>
</html>